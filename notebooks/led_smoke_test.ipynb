{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LED-base Smoke Test\n",
        "\n",
        "A tiny end-to-end sanity check for the `allenai/led-base-16384` model that the paper uses as the encoderâ€“decoder baseline. It constructs a single inline example, loads the pretrained checkpoint, and generates one summary so you can confirm Transformers + CUDA are wired up (no dataset files required)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "%pip install -q transformers==4.41.0 accelerate==0.28.0 sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8ba0ab4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"HF_TOKEN\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Reference summary ===\n",
            "You were hospitalized for pneumonia that caused trouble breathing. We treated you with oxygen and antibiotics, you improved, and you can continue medication at home before seeing your primary doctor.\n",
            "\n",
            "=== LED generation ===\n"
          ]
        }
      ],
      "source": [
        "# @title Run LED-base on a single inline example\n",
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "MODEL_ID = \"allenai/led-base-16384\"  # @param {\"type\": \"string\"}\n",
        "\n",
        "example = {\n",
        "    \"text\": (\n",
        "        \"Brief Hospital Course: Mr. Smith came in with fever, productive cough, and shortness of breath. \"\n",
        "        \"Imaging was consistent with pneumonia and he required oxygen for two days. Antibiotics and inhalers were started, \"\n",
        "        \"his breathing improved, and he was discharged home on day 4 with a plan for primary care follow-up.\"\n",
        "    ),\n",
        "    \"summary\": (\n",
        "        \"You were hospitalized for pneumonia that caused trouble breathing. We treated you with oxygen and antibiotics, \"\n",
        "        \"you improved, and you can continue medication at home before seeing your primary doctor.\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "print(\"=== Reference summary ===\")\n",
        "print(example[\"summary\"])\n",
        "print(\"\\n=== LED generation ===\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID)\n",
        "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()\n",
        "\n",
        "inputs = tokenizer(\n",
        "    example[\"text\"],\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True,\n",
        "    max_length=2048,\n",
        ")\n",
        "inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "with torch.inference_mode():\n",
        "    generation = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=256,\n",
        "        num_beams=4,\n",
        "    )\n",
        "decoded = tokenizer.decode(generation[0], skip_special_tokens=True)\n",
        "print(decoded)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
