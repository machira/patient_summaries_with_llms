{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fdivlIun9ELP",
      "metadata": {
        "id": "fdivlIun9ELP"
      },
      "source": [
        "# Paper Reproduction Launcher (LED only)\n",
        "\n",
        "This Colab-friendly notebook drives the existing CLI scripts in `summarization/` to run very small LED and Llama jobs. It uses the `train_last_100.json` / `valid_last_100.json` splits so we can exercise the full code paths quickly before launching the long runs described in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3Dm4wULVsBDi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dm4wULVsBDi",
        "outputId": "6c61c8e0-46ca-4bc0-e890-5bae97c076c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/patient_summaries_with_llms\n"
          ]
        }
      ],
      "source": [
        "# @title Sync the local repository from Google Drive (no git clone)\n",
        "from pathlib import Path\n",
        "import os\n",
        "import importlib.util\n",
        "\n",
        "COLAB = importlib.util.find_spec(\"google.colab\") is not None\n",
        "if COLAB:\n",
        "    from google.colab import drive  # type: ignore\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    REPO_IN_DRIVE = Path('/content/drive/Othercomputers/My Mac/patient_summaries_with_llms/')  # @param {type:\"string\"}\n",
        "    if not REPO_IN_DRIVE.exists():\n",
        "        raise FileNotFoundError(f\"Upload/sync the local repo to {REPO_IN_DRIVE} first.\")\n",
        "    TARGET_DIR = Path('/content/patient_summaries_with_llms')\n",
        "    TARGET_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    os.system(f\"rsync --progress -a --delete '{REPO_IN_DRIVE}/summarization' '{TARGET_DIR}/'\")\n",
        "    os.system(f\"rsync --progress -a --delete '{REPO_IN_DRIVE}/data' '{TARGET_DIR}/'\")\n",
        "    os.system(f\"rsync --progress -a --delete '{REPO_IN_DRIVE}/requirements.txt' '{TARGET_DIR}/'\")\n",
        "    os.system(f\"rsync --progress -a --delete '{REPO_IN_DRIVE}/requirements-llama.txt' '{TARGET_DIR}/'\")\n",
        "    %cd /content/patient_summaries_with_llms\n",
        "else:\n",
        "    print(\"Running outside Colab; using the current working directory.\")\n",
        "    TARGET_DIR = Path.cwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "18ff9a35",
      "metadata": {
        "id": "18ff9a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44452539-b3cd-4cc7-d6b1-2c9649d10644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.9/150.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m725.0/725.0 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentencepiece (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for erlastic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "google-adk 1.19.0 requires PyYAML<7.0.0,>=6.0.2, but you have pyyaml 6.0.1 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# @title Install base dependencies shared by LED + evaluation\n",
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mYhT_Mdx9ELR",
      "metadata": {
        "id": "mYhT_Mdx9ELR"
      },
      "source": [
        "## LED smoke run (`summarization/run_summarization.py`)\n",
        "\n",
        "Trains/evaluates `allenai/led-base-16384` on the last 100 training examples for one epoch to ensure that tokenization, dataloading, and Trainer hooks work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7T8Yq6uq9ELR",
      "metadata": {
        "id": "7T8Yq6uq9ELR",
        "tags": [
          "bash"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a4464a-5b18-4605-d1ef-089875b470a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-06 10:32:44.776377: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765017164.799561    4201 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765017164.806465    4201 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765017164.824469    4201 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765017164.824513    4201 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765017164.824516    4201 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765017164.824518    4201 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n",
            "12/06/2025 10:32:55 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
            "12/06/2025 10:32:55 - INFO - __main__ -   Training/evaluation parameters Seq2SeqTrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=True,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "generation_config=None,\n",
            "generation_max_length=None,\n",
            "generation_num_beams=None,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=results/led_full_run_predict/runs/Dec06_10-32-53_42c6e6b019d8,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "output_dir=results/led_full_run_predict,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=8,\n",
            "predict_with_generate=True,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['wandb'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=results/led_full_run_predict,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "sortish_sampler=False,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "Generating test split: 100 examples [00:00, 4101.69 examples/s]\n",
            "loading configuration file data/led_4000_600_chars/config.json\n",
            "Model config LEDConfig {\n",
            "  \"_name_or_path\": \"data/led_4000_600_chars/\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"LEDForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"attention_window\": [\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024,\n",
            "    1024\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 12,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 12,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_decoder_position_embeddings\": 1024,\n",
            "  \"max_encoder_position_embeddings\": 16384,\n",
            "  \"model_type\": \"led\",\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file vocab.json\n",
            "loading file merges.txt\n",
            "loading file tokenizer.json\n",
            "loading file added_tokens.json\n",
            "loading file special_tokens_map.json\n",
            "loading file tokenizer_config.json\n",
            "loading weights file data/led_4000_600_chars/model.safetensors\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 1\n",
            "}\n",
            "\n",
            "All model checkpoint weights were used when initializing LEDForConditionalGeneration.\n",
            "\n",
            "All the weights of LEDForConditionalGeneration were initialized from the model checkpoint at data/led_4000_600_chars/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use LEDForConditionalGeneration for predictions without further training.\n",
            "loading configuration file data/led_4000_600_chars/generation_config.json\n",
            "Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 0,\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"pad_token_id\": 1\n",
            "}\n",
            "\n",
            "Map:   0% 0/100 [00:00<?, ? examples/s]/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:3892: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Map: 100% 100/100 [00:00<00:00, 1068.62 examples/s]\n",
            "Downloading builder script: 6.14kB [00:00, 11.9MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n",
            "12/06/2025 10:32:58 - INFO - __main__ -   *** Test ***\n",
            "***** Running Prediction *****\n",
            "  Num examples = 100\n",
            "  Batch size = 1\n",
            "Input ids are automatically padded from 331 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  0% 0/100 [00:00<?, ?it/s]Input ids are automatically padded from 421 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  2% 2/100 [00:00<00:48,  2.01it/s]Input ids are automatically padded from 254 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  3% 3/100 [00:01<01:08,  1.41it/s]Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  4% 4/100 [00:03<01:19,  1.21it/s]Input ids are automatically padded from 399 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  5% 5/100 [00:04<01:31,  1.04it/s]Input ids are automatically padded from 369 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  6% 6/100 [00:05<01:30,  1.03it/s]Input ids are automatically padded from 773 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  7% 7/100 [00:06<01:31,  1.01it/s]Input ids are automatically padded from 538 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  8% 8/100 [00:07<01:33,  1.01s/it]Input ids are automatically padded from 874 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "  9% 9/100 [00:08<01:29,  1.02it/s]Input ids are automatically padded from 354 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 10% 10/100 [00:09<01:29,  1.00it/s]Input ids are automatically padded from 741 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 11% 11/100 [00:10<01:28,  1.00it/s]Input ids are automatically padded from 812 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 12% 12/100 [00:11<01:29,  1.02s/it]Input ids are automatically padded from 617 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 13% 13/100 [00:12<01:27,  1.01s/it]Input ids are automatically padded from 390 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 14% 14/100 [00:13<01:26,  1.01s/it]Input ids are automatically padded from 855 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 15% 15/100 [00:14<01:36,  1.14s/it]Input ids are automatically padded from 416 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 16% 16/100 [00:16<01:44,  1.24s/it]Input ids are automatically padded from 119 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 17% 17/100 [00:17<01:38,  1.18s/it]Input ids are automatically padded from 675 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 18% 18/100 [00:18<01:32,  1.12s/it]Input ids are automatically padded from 722 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 19% 19/100 [00:19<01:28,  1.09s/it]Input ids are automatically padded from 576 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 20% 20/100 [00:20<01:27,  1.09s/it]Input ids are automatically padded from 672 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 21% 21/100 [00:21<01:28,  1.12s/it]Input ids are automatically padded from 945 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 22% 22/100 [00:22<01:25,  1.09s/it]Input ids are automatically padded from 501 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 23% 23/100 [00:23<01:18,  1.02s/it]Input ids are automatically padded from 643 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 24% 24/100 [00:24<01:18,  1.03s/it]Input ids are automatically padded from 375 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 25% 25/100 [00:25<01:17,  1.04s/it]Input ids are automatically padded from 445 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 26% 26/100 [00:26<01:15,  1.02s/it]Input ids are automatically padded from 665 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 27% 27/100 [00:27<01:16,  1.05s/it]Input ids are automatically padded from 453 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 28% 28/100 [00:29<01:28,  1.22s/it]Input ids are automatically padded from 856 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 29% 29/100 [00:30<01:24,  1.19s/it]Input ids are automatically padded from 699 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 30% 30/100 [00:32<01:51,  1.60s/it]Input ids are automatically padded from 952 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 31% 31/100 [00:34<01:42,  1.48s/it]Input ids are automatically padded from 289 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 32% 32/100 [00:35<01:32,  1.36s/it]Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 34% 34/100 [00:37<01:17,  1.17s/it]Input ids are automatically padded from 498 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 35% 35/100 [00:38<01:15,  1.16s/it]Input ids are automatically padded from 795 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 36% 36/100 [00:39<01:13,  1.14s/it]Input ids are automatically padded from 743 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 37% 37/100 [00:40<01:07,  1.07s/it]Input ids are automatically padded from 512 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 38% 38/100 [00:41<01:06,  1.08s/it]Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 39% 39/100 [00:42<01:05,  1.08s/it]Input ids are automatically padded from 401 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 40% 40/100 [00:43<01:03,  1.07s/it]Input ids are automatically padded from 568 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 42% 42/100 [00:45<01:02,  1.07s/it]Input ids are automatically padded from 524 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 43% 43/100 [00:46<00:59,  1.05s/it]Input ids are automatically padded from 431 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 44% 44/100 [00:47<00:57,  1.03s/it]Input ids are automatically padded from 589 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 45% 45/100 [00:48<00:55,  1.01s/it]Input ids are automatically padded from 406 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 46% 46/100 [00:49<00:54,  1.01s/it]Input ids are automatically padded from 970 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 47% 47/100 [00:50<00:56,  1.07s/it]Input ids are automatically padded from 458 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 48% 48/100 [00:51<00:55,  1.07s/it]Input ids are automatically padded from 604 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 49% 49/100 [00:53<01:07,  1.31s/it]Input ids are automatically padded from 529 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 50% 50/100 [00:54<01:01,  1.22s/it]Input ids are automatically padded from 825 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 51% 51/100 [00:55<00:56,  1.16s/it]Input ids are automatically padded from 738 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 52% 52/100 [00:56<00:53,  1.12s/it]Input ids are automatically padded from 345 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 53% 53/100 [00:57<00:50,  1.07s/it]Input ids are automatically padded from 563 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 54% 54/100 [00:58<00:49,  1.07s/it]Input ids are automatically padded from 575 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 56% 56/100 [01:00<00:44,  1.01s/it]Input ids are automatically padded from 852 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 57% 57/100 [01:01<00:43,  1.00s/it]Input ids are automatically padded from 419 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 58% 58/100 [01:02<00:42,  1.01s/it]Input ids are automatically padded from 794 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 59% 59/100 [01:03<00:40,  1.02it/s]Input ids are automatically padded from 305 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 60% 60/100 [01:04<00:39,  1.01it/s]Input ids are automatically padded from 500 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 61% 61/100 [01:05<00:39,  1.01s/it]Input ids are automatically padded from 450 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 62% 62/100 [01:06<00:38,  1.02s/it]Input ids are automatically padded from 637 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 63% 63/100 [01:07<00:37,  1.01s/it]Input ids are automatically padded from 224 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 64% 64/100 [01:08<00:36,  1.03s/it]Input ids are automatically padded from 341 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 65% 65/100 [01:09<00:34,  1.00it/s]Input ids are automatically padded from 811 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 67% 67/100 [01:12<00:35,  1.07s/it]Input ids are automatically padded from 544 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 68% 68/100 [01:13<00:33,  1.06s/it]Input ids are automatically padded from 465 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 69% 69/100 [01:14<00:33,  1.07s/it]Input ids are automatically padded from 466 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 70% 70/100 [01:15<00:31,  1.06s/it]Input ids are automatically padded from 442 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 72% 72/100 [01:17<00:28,  1.03s/it]Input ids are automatically padded from 207 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 73% 73/100 [01:18<00:29,  1.08s/it]Input ids are automatically padded from 960 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 74% 74/100 [01:19<00:28,  1.08s/it]Input ids are automatically padded from 914 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 75% 75/100 [01:20<00:26,  1.07s/it]Input ids are automatically padded from 930 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 76% 76/100 [01:21<00:25,  1.07s/it]Input ids are automatically padded from 769 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 77% 77/100 [01:22<00:25,  1.10s/it]Input ids are automatically padded from 754 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 78% 78/100 [01:23<00:23,  1.07s/it]Input ids are automatically padded from 955 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 79% 79/100 [01:24<00:22,  1.05s/it]Input ids are automatically padded from 264 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 80% 80/100 [01:25<00:21,  1.06s/it]Input ids are automatically padded from 608 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 81% 81/100 [01:27<00:20,  1.08s/it]Input ids are automatically padded from 340 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 82% 82/100 [01:28<00:19,  1.06s/it]Input ids are automatically padded from 661 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 83% 83/100 [01:29<00:17,  1.04s/it]Input ids are automatically padded from 295 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 84% 84/100 [01:30<00:16,  1.06s/it]Input ids are automatically padded from 981 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 85% 85/100 [01:31<00:15,  1.04s/it]Input ids are automatically padded from 503 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 86% 86/100 [01:32<00:14,  1.02s/it]Input ids are automatically padded from 217 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 87% 87/100 [01:33<00:14,  1.12s/it]Input ids are automatically padded from 590 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 88% 88/100 [01:34<00:12,  1.05s/it]Input ids are automatically padded from 438 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 89% 89/100 [01:35<00:11,  1.05s/it]Input ids are automatically padded from 277 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 90% 90/100 [01:36<00:10,  1.05s/it]Input ids are automatically padded from 664 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 91% 91/100 [01:37<00:09,  1.10s/it]Input ids are automatically padded from 267 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 92% 92/100 [01:38<00:08,  1.07s/it]Input ids are automatically padded from 489 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 93% 93/100 [01:39<00:07,  1.14s/it]Input ids are automatically padded from 352 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 94% 94/100 [01:40<00:06,  1.09s/it]Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 95% 95/100 [01:41<00:05,  1.06s/it]Input ids are automatically padded from 641 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 96% 96/100 [01:42<00:04,  1.06s/it]Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 97% 97/100 [01:44<00:03,  1.27s/it]Input ids are automatically padded from 367 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            " 98% 98/100 [01:45<00:02,  1.22s/it]Input ids are automatically padded from 983 to 1024 to be a multiple of `config.attention_window`: 1024\n",
            "100% 100/100 [01:49<00:00,  1.10s/it]\n",
            "***** test metrics *****\n",
            "  test_gen_len            =     145.79\n",
            "  test_loss               =     1.8646\n",
            "  test_rouge1             =      43.21\n",
            "  test_rouge2             =    15.9021\n",
            "  test_rougeL             =    27.5519\n",
            "  test_rougeLsum          =    40.4693\n",
            "  test_runtime            = 0:01:51.73\n",
            "  test_samples            =        100\n",
            "  test_samples_per_second =      0.895\n",
            "  test_steps_per_second   =      0.895\n",
            "Downloading builder script: 7.95kB [00:00, 14.9MB/s]\n",
            "Downloading builder script: 12.1kB [00:00, 18.5MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 110kB/s]\n",
            "config.json: 100% 482/482 [00:00<00:00, 2.13MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 3.89MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 2.09MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 2.09MB/s]\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/merges.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/tokenizer.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-large\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "model.safetensors: 100% 1.42G/1.42G [00:04<00:00, 324MB/s]\n",
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59/model.safetensors\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "tokenizer_config.json: 100% 52.0/52.0 [00:00<00:00, 230kB/s]\n",
            "config.json: 100% 729/729 [00:00<00:00, 2.95MB/s]\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-large-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"CONTRADICTION\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"ENTAILMENT\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 0,\n",
            "    \"ENTAILMENT\": 2,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "vocab.json: 899kB [00:00, 128MB/s]\n",
            "merges.txt: 456kB [00:00, 108MB/s]\n",
            "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/vocab.json\n",
            "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/merges.txt\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/tokenizer_config.json\n",
            "loading file tokenizer.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-large-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"CONTRADICTION\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"ENTAILMENT\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 0,\n",
            "    \"ENTAILMENT\": 2,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/config.json\n",
            "Model config DebertaConfig {\n",
            "  \"_name_or_path\": \"microsoft/deberta-large-mnli\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"CONTRADICTION\",\n",
            "    \"1\": \"NEUTRAL\",\n",
            "    \"2\": \"ENTAILMENT\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"CONTRADICTION\": 0,\n",
            "    \"ENTAILMENT\": 2,\n",
            "    \"NEUTRAL\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 1024,\n",
            "  \"pos_att_type\": [\n",
            "    \"c2p\",\n",
            "    \"p2c\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"relative_attention\": true,\n",
            "  \"transformers_version\": \"4.38.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "pytorch_model.bin: 100% 1.62G/1.62G [00:03<00:00, 411MB/s] \n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--microsoft--deberta-large-mnli/snapshots/7296194b9009373def4f7c5dad292651e4b5cf4e/pytorch_model.bin\n",
            "All the weights of DebertaModel were initialized from the model checkpoint at microsoft/deberta-large-mnli.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaModel for predictions without further training.\n",
            "Test examples:\n",
            "\n",
            "\n",
            "\n",
            "Example 0:\n",
            "\n",
            "Brief Hospital Course: Mr. ___ was admitted to the vascular surgery service at the ___ for management of his worsening RLE Cellulitis that was unimproved following a 1 week course of PO Augmentin. He was started on IV antibiotics and his RLE was monitored frequently by the inpatient service. We saw interval improvements over the following days; he was encouraged to elevate his legs as often as possible to help with the swelling. Several days into his admission, the patient began to complain of some nausea, epigastric discomfort, odynophagia and the feeling of food being stuck in his throat. His PO intake of solid foods was minimal and he did endorse several episodes of small volume emesis. Due to his positive smoking history, we consulted GI and the patient underwent an EGD, which demonstrate two duodenal ulcers with one visible underlying vessel. The ulcer was injected with Epinephrine and cauterized. No samples for biopsy was taken, however, we did obtain a stool sample from the patient for H. Pylori testing. The patient was started on a PPI BID and was discharged home the following day when his blood levels were deemd stable. He was instructed to follow up with PCP in ___ regarding the final results of his H. Pylori test and was told that his PCP would administer any additional medications regarding treatment. Prior to discharge, he was tolerating a regular diet, voiding, ambulating with some support and his pain was controlled with PO medications. He was discharged home with services and was given the appropriate information regarding follow up.\n",
            "\n",
            "You were admitted to the ___ for management of your right leg cellulitis. You were started on IV antibiotics on your admission and transitioned to oral antibiotics throughout your stay. Your cellulitis has improved throughout your stay. We also explored your mixed symptoms of nausea, difficulty swallowing and epigastric pain. We spoke with the GI team who performed an upper endoscopy on ___. This study found 2 small ulcers in your duodenum as the likely cause of your symptoms. These kinds of ulcers are almost always caused by a bacterial infection called H. Pylori. We sent your stool off for studies to confirm this diagnosis and started you on a PPI call Omeprazole, a medication that helps with the symptoms you have been experiencing. Please take this medication two times per day, 30 minutes before meals.\n",
            "\n",
            "You were admitted to the vascular surgery service at the ___ for management of your right leg cellulitis. You were treated with IV antibiotics and your leg swelling improved. You were also seen by the gastroenterology team and underwent an EGD, which showed two duodenal ulcers. The ulcer was cauterized and the bleeding stopped. You were started on a medication called pantoprazole to help prevent further ulcers. You should continue to take this medication until you see your primary care doctor. You were also found to have a bacteria called H. Pylori. This bacteria can cause ulcers and can cause ulcers. You should discuss this with your primary care doctor.\n",
            "\n",
            "\n",
            "\n",
            "Example 1:\n",
            "\n",
            "Brief Hospital Course: Ms. ___ is an ___ woman with history of sCHF, pAF, CHB s/p PPM, HLD, COPD who presented for ERCP. ACUTE/ACTIVE PROBLEMS: # Common bile duct stricture: underwent stent placement and sphincterotomy with ERCP on ___. Apixaban was held for 48 hours pre and post procedure. She was tolerating a regular diet at time of discharge. CBD brushings were sent and remain pending. Given severe iodinated contrast allergy, plan is to attempt MRCP as outpatient to evaluate for underlying pancreatic mass causing extrinsic CBD compression. Outpatient providers notified of need for MRCP arrangement with cardiology assistance in the setting of pacemaker dependence. # ___ systolic congestive CHF: LVEF 35%. Patient euvolemic on admission. She received hydration overnight post-procedure and home torsemide was then resumed. Also continued home losartan and metoprolol # Anemia: undergoing outpatient workup. No evidence of bleeding here. Hgb dropped initially post-procedure likely due to hemodilution, stable on day of discharge. # Atrial fibrillation: Continued home metoprolol. Apixaban was held post-procedurally as above. Patient instructed to restart on ___ ___. Transitional Issues: ==================== - CBD brushings pending at time of discharge - CA ___ pending at time of discharge - apixaban on hold 48 hours post procedure, to be resumed on evening of ___ - needs repeat ERCP in 4 weeks for stent pull and re-evaluation - would benefit from outpatient MRCP to better evaluate for pancreatic mass causing extrinsic compression. This may be possible given pacemaker type but will require coordination with EP (email sent on day of discharge to EP, cardiology, Dr. ___ PCP) [x]> 30 minutes spent on discharge planning and coordination on day of discharge\n",
            "\n",
            "You came in to have an ERCP procedure. The procedure showed narrowing of your bile duct. A stent was placed to open up the narrowed area and samples were taken. It will be very important to follow up with the ERCP team as an outpatient. You will need another ERCP in four weeks to remove the stent. You can restart all of your medications as scheduled on discharge. Due to the narrowing of your bile duct, it is recommended that you undergo an MRCP (MRI of the bile ducts and pancreas) to evaluate for a cause of the narrowing. This will require coordination with your primary care doctor, cardiologist and Dr. ___. I have been in touch with them to start this process.\n",
            "\n",
            "You were admitted to the hospital for a procedure called an ERCP to relieve a stricture in your common bile duct. You had a stent placed and a sphincterotomy performed. You tolerated the procedure well. You will need to have a repeat ERCP in 4 weeks to remove the stent and re-evaluate. You will need to hold your apixaban for 48 hours post procedure to allow for the stent to be removed. You will need to have your blood drawn on ___ to check your blood counts. You will need to have your labs drawn on ___ and have the results sent to your outpatient cardiologist.\n",
            "\n",
            "\n",
            "\n",
            "Example 2:\n",
            "\n",
            "Brief Hospital Course: Ms ___ is a ___ year old female who was admitted with generalized weakness. She has a known history of ___ treated with Sinemet, which was recently uptitrated. I spoke with her neurologist who feels the current dosing is appropriate. Her fatigue and weakness we felt was secondary to deconditioning in the setting of her ___ for which we felt she needs rehab for reconditioning. We also noted she had a UTI which may be contributing - she was started on IV ceftriaxone which she should continue up through ___. Her warfarin was initially held because of an INR of 4.6; unclear why she was supratherapeutic. Her coumadin was held initially down immediate downtrend of INR to 1.6; she was started on warfarin on ___ at 3 mg; this will need to be checked daily as she is on concomittant antibiotics. She was otherwise continued on her other home medications. At time of discharge, her medication regimen was simplified by discontinuation of simvastatin, reduction in omeprazole from BID to daily. Her daughter will ensure that she sees her primary care doctor in the next 2 weeks.\n",
            "\n",
            "You were admitted for fatigue and weakness which we felt was from a urinary tract infection in the setting of your ___ disease. To treat this, we started you on IV antibiotics. We also spoke with your neurologist who agreed with this plan. We had physical therapy see you as well; we felt it best that you spend some time in a rehab setting to get your muscles stronger again. We also made some medication adjustments, including stopping your simvastatin, decreasing your omeprazole dose, and holding your coumadin until your INR decreased (it was high on admission). We restarted coumadin just before discharge; your rehab will be checking your INR to ensure you are on the right dose.\n",
            "\n",
            "You were admitted to the hospital with weakness and fatigue. We felt this was due to deconditioning from your ___ and deconditioning from your ___. We also noted that you had a urinary tract infection which may be contributing to your weakness. We started you on IV antibiotics and you should continue this for a total of 7 days. We also stopped your simvastatin and reduced your omeprazole from twice a day to once a day. We also stopped your warfarin because your INR was too high. We started you on a new medication called coumadin. You will need to have your INR checked daily.\n",
            "\n",
            "\n",
            "\n",
            "Example 3:\n",
            "\n",
            "Brief Hospital Course: Ms. ___ is a ___ year old lady with PMH of only asthma who presents with increasing dyspnea on exertion, ___ edema, who is found to have a new diagnosis of systolic heart failure with an EF of 20%. A left heart cath was done that did not show CAD. She was successfully diuresed on IV Lasix and then transitioned to po Lasix. A cardiac MRI was also done that did not show any abnormalities within the heart but a moderate-sized right-sided pleural effusion and a wedge-shaped area of consolidation in the right lower lung lobe was seen. A chest CT was then ordered that showed small right pleural effusion with an in capsulated masslike lesion at the lateral posterior aspect of the right chest wall. Thought to be infectious v. atelectasis v. aspiration and radiology states that it is resolving since last CT in ___. # Acute Onset Systolic CHF: Etiology is unknown at this point. Ischemic etiology was ruled out as catherization did not show any CAD. Myocarditis could be a possibility considering recent URI; however, no troponins and viral panel has thus far been negative. ___ antibody was sent but still pending. HIV and parvovirus has been negative. An MRI was done on ___ that did not show any abnormalities. She was diuresed with IV Lasix and then transitioned to po. Sprinolactone, lisinopril, and metoprolol were also started. # New 1.9 cm Subpleural Nodule and 2.1 right lung base nodular opacity : CT Chest showed multiple nodules and concern for a infiltrative process v. infection. Less likely to be malignancy considering no smoking history and multiple nodules. CHRONIC ISSUES # Asthma: continue home albuterol as needed DISCHARGE WEIGHT: 271 lb or 123 kg. TRANSITIONAL ISSUES =================== [ ]SPIRONOLACTONE/FOLLOW-LABS: Started spironolactone at this admission. Need to follow K+ by ___ [ ]PLEURAL EFFUSIONS/WEDGE SHAPED CONSOLIDATION/PULMONARY NODULES: Found on CT chest and thought to be resolving as it has decreased in size since last CT Chest in ___. Please repeat chest CT in ___ weeks to confirm nodule resolution. LAB FOLLOW-UP: Please follow up CRP, ESR, ACE level, ___ FINAL CARDIAC MRI READ: Please follow-up the final cardiac MRI report as we read a preliminary read. NEW MEDICATIONS =============== Lasix (furosemide) 20 mg daily Metoprolol succinate XL 50 mg Sprinolactone 12.5 mg daily Lisinopril 15 mg daily\n",
            "\n",
            "You were admitted to ___ for a new congestive heart failure diagnosis. While you were here, we started you on an IV diuretic, which is a medication that helps you urinate. We then transitioned you over to an oral diuretic for you to take at home called Lasix (furosemide). We also started you on spironolactone, metoprolol, and lisinopril, which are medications for your heart failure. A left heart catherization did not show any blockages in your heart arteries. A cardiac MRI was also done, which did not show us why you have congestive heart failure. YOUR DISCHARGE WEIGHT: 123.1 kg or 271 lbs. Please weight yourself every morning at the same time.\n",
            "\n",
            "You were admitted to the hospital because you were having trouble breathing. We did a procedure called a cardiac catheterization that did not show any blockages in the arteries of your heart. We also did an MRI of your heart that did not show any abnormalities. We also did a CT scan of your chest that showed a small amount of fluid in your right lung. We think this is due to a small amount of fluid in your lungs. We gave you a diuretic medication through the IV to help get the fluid out. We also did a CT scan of your chest that showed a small amount of fluid in your right lung. We think this is resolving.\n",
            "\n",
            "\n",
            "\n",
            "Example 4:\n",
            "\n",
            "Brief Hospital Course: Ms. ___ is a ___ y/o female who presented to the ___ ___ on ___ s/p fall down 15 stairs. Injuries included a right pelvic fracture, right orbital floor fracture, right elbow fracture and a small right subarachnoid hemorrhage. She was admitted to the Trauma Surgery service for further medical care. On HD1, the Orthopaedic Surgery service evaluated the patient's right elbow and right pelvic fractures. The right elbow required surgery and the pelvic fracture was managed non-operatively, WBAT. The Plastic Surgery service evaluated the patient's facial fractures and recommended sinus precautions. Ophthalmology was consulted and determined no right globe injury. The Neurosurgery team recommended obtaining a MRA Head to rule out aneurysm in the setting of hemorrhage in the sylvian fissure, and there was no aneurysm detected. No intervention was necessary. On HD2, the patient was taken to the operating room with the Orthopaedic Surgery service and underwent ORIF of the right elbow fracture. The patient tolerated this procedure well (reader, please see operative note for details). After remaining hemodynamically stable in the PACU, the patient was transferred to the surgical floor. On POD #1, the patient's cervical collar was clinically cleared. On HD3-5, patient clinically progressed and had reduction in her pain medication requriment. Patient was assessed by ___, who suggested rehab placement due to her ultiple fractures and functioning well below baseline. She was assessed by Neurosurgery who noted no need for further neurosurgical workup. Patient remained on sinus precautions, with plan to followup with Plastics/PRS 2 weeks post-discharge to evaluate her facial fractures. Plan was also made for patient to followup in orthopedics clinic for f/u up of her pelvic fracture and radial-ulnar fracture s/p ORIF.\n",
            "\n",
            "You were admitted to the hospital after a fall down the stairs and were found to have right facial injuries, right hip fractures, a right elbow fracture, and a small internal head bleed. The Neurosurgery service evaluated you for your head bleed and no intervention was necessary. The Plastic Surgery service evaluated your facial fractures and recommended you remain on Sinus Precautions (please see below for instructions) for the next two weeks. The Ophthalmology service ruled out any injury to your eye. The Orthopaedics service determined an operation was necessary to fix your right elbow fracture and you were taken to the Operating Room for surgical repair. You tolerated this procedure well and were placed in a splint. Please do not bear weight on your right arm until you are cleared to do so by the Orthopaedic Surgery team. Your right pelvic fracture did not require surgery and you may bear weight as tolerated on your right leg. You have worked with Occupational and Physical Therapy and it is recommended that you be discharged to rehab to regain your strength. You are now ready to be discharged from the hospital.\n",
            "\n",
            "You were admitted to the hospital after a fall. You sustained fractures to your right elbow, right elbow and pelvis. You were taken to the operating room and underwent repair of your elbow fracture. You tolerated this procedure well. You were seen by the Plastic Surgery service, who recommended sinus precautions. You were seen by the Neurosurgery service, who recommended obtaining an MRA Head to rule out aneurysm in the setting of hemorrhage in the sylvian fissure. There was no aneurysm detected. No intervention was necessary. You were seen by the Orthopaedic Surgery service, who recommended that you wear your cervical collar for comfort. You were seen by the Orthopaedic Surgery service, who recommended that you have your right elbow repaired in the outpatient setting.\n",
            "\n",
            "\n",
            "\n",
            "Example 5:\n",
            "\n",
            "Brief Hospital Course: A/P: This is a ___ yo woman hypertension and h/o thoracic pain who presents with atypical chest pain. # Chest pain: Very unlikely to be cardiac etiology given duration of symptoms 24 hours prior to negative cardiac enzymes. More likely to be musculoskeletal given h/o thoracic pain but also consider GI etiology. CTA wet read negative for PE or dissection. She has been evaluated for the back pain and it was thought due to djd. - aspirin 325mg daily, enalapril; ccb relatively contraindicated in active coronary ischemia but very low clinical suspicion so will continue verapamil. Cardiac enzymes were negative x2, with the first set at least 24 hrs after onset of symptoms. - lipids and hgb a1c for risk modification-pending on d/c - Pt will call on ___ morning for outpatient stress echo. # GERD: Pt's GERD symptoms worsened since ___ when her Oxybutynin dose increased from 5 to 10mg. Pt had increased reflux 3 days PTA and day prior to chest pain. d/c with Omeprazole. # Hypertension: continue hctz, enalapril, verapamil as above. # Hypothyroidism: continue levothyroxine. # Urge incontinence: continue ditropan; pt reports increased side effects (dry mouth, possibly heart burn) on 10mg/day, so will return to 5mg/day, which had some benefit with more acceptable side effects. # Unexplained weight loss: has been worked up with EGD, colonoscopy, etc, as outpt; defer further workup to Dr ___.\n",
            "\n",
            "You were admitted with intermittent chest pain that radiate from your back to front. In emergency department, computed tomography angiogram (CTA) showed no pulmonary embolism which can be life threatening. The cardiac enzyme and electrocardiogram did not show acute ischemia of your heart. We believe your atypical chest pain is likely due to musculoskeletal or gastroesophageal reflux symptoms. We started prilosec (omeprazole) for acid reflux and you can continue taking tylenol (acetaminophen) for costochondritis. The presence of jaw pain, however, is somewhat concerning for a heart problem. We recommend a stress echo test of the heart to rule out this possible cause of your symptoms.\n",
            "\n",
            "You were admitted to the hospital with chest pain. You had a CT scan of your chest which did not show any evidence of a blood clot or dissection. You were also evaluated for your back pain and it was thought to be due to your chronic pain. You were also evaluated for your chest pain with a CT scan of your chest which did not show any evidence of a blood clot or dissection. You were also evaluated for your reflux and your heart was found to be functioning normally. You were also evaluated for your chest pain with blood tests and EKGs. You were found to have no evidence of a heart attack.\n",
            "\n",
            "\n",
            "\n",
            "Example 6:\n",
            "\n",
            "Brief Hospital Course: Ms. ___ is a ___ w/ morbid obesity, PCOS, OSA, overactive bladder who presents with dyspnea, currently on heparin bridge to warfarin for presumed PE. ACTIVE ISSUES # Presumed PE: Patient has Wells score of 7, making her high probability for PE. Risk factors include sudden onset SOB, hemoptysis, tachycardia, morbid obesity, relative immobility with recent knee pain, family history of blood clots, Mirena IUD. She also had elevated D-dimer and RV dilation on TTE. Her size precluded her from a VQ scan or CT with pulmonary angiography for diagnosis. OSH lower extremity U/S was also unrevealing (poor quality study). Evaluated by cardiology for pulmonary angiogram in the cath lab but also unable to perform given size. Given high probability, treatment for PE was initiated with IV heparin drip and coumadin. Her INR is still subtherapeutic despite increasing doses of Coumadin. Will need continuation of heparin gtt and up-titration of coumadin until INR therapeutic. Her INR at discharge was 1.4. # Hypoxia: Question whether due to PE vs longstanding right heart failure. BNP high. Cardiology recommended against Lasix given preload dependence. Will treat for PE as above. Oxygen requirement improving at discharge. Patient was also not always agreeable to wear CPAP. # Pneumonia: No fevers, no leukocytosis, but does have some infiltration on CXR and productive cough, now improved. Treated for CAP, now s/p 7 day course of levofloxacin. # Atrial Fibrillation: Tachypneic and tachycardic. ___ be from PE, or possible pneumonia. Treating PE vs pneumonia as above. Started on metoprolol for rate control and uptitrated. On anticoagulation for treatment of PE as above. # Right Knee Dislocation: Reduced, post-reduction films with better alignment. Evaluated by Ortho and cannot use knee immobilizer given body habitus. Patient is WBAT. # Impaired Glucose Tolerance: Patient has HbA1c 6.2. Lifestyle changes are mainstay treatment but could also consider metformin for prevention, as sometimes recommended in select patient groups for which lifestyle modification not achievable (eg BMI >35). CHRONIC ISSUES # GERD: Continued home omeprazole. # Depression: Continued home fluoxetine. # OSA: Continue CPAP although patient not always agreeable to wear. Transitional Issues: - Please continue heparin drip and warfarin until INR is in therapeutic range (INR ___ for 24 hours then can discontinue heparin. Patient may need further up-titration of her coumadin dosing to achieve therapeutic INR. Patient should follow-up in the ___ at ___. - Patient will require 6 months of anticoagulation with coumadin, at this time please re-assess need for continuation. - Please assess need for cardioversion if atrial fibrillation is persisent in several months. - Please consider removal of Mirena IUD given potential risk of PE. - Please titrate metoprolol for HR goal < 100. - Please ensure patient has follow-up appointment with her primary care physician upon discharge. - Consider starting metformin for impaired glucose tolerance given morbid obesity. - Please d/c PICC once INR is therapaeutic and no need for herparin.\n",
            "\n",
            "You were admitted to the hospital because you were having severe shortness of breath as well as low blood oxygen levels. We were concerned that you had a pulmonary embolism (blood clot in your lung) and you were started on anticoagulation to thin your blood and dissolve the clots. You will need to take coumadin (blood thinning medication) for at least 3 to 6 months. There was also a concern that you had pneumonia and finished a course of antibiotics. You also had a patellar dislocation in your right knee that was placed back to its normal position. Unfortuneately we were unable to place a brace to stabilize your knee. Please take great care when moving your leg.\n",
            "\n",
            "You were admitted to the hospital because you were having shortness of breath. You were found to have a blood clot in your lungs. You were started on a blood thinner called heparin to prevent further clots. You will need to continue taking warfarin until your INR is therapeutic. You were also found to have a pneumonia. You were started on antibiotics for this. You were also found to have a fast heart rate. You were started on a medication called metoprolol to help control your heart rate. You should continue taking warfarin until your INR is therapeutic. You should continue taking coumadin until your INR is therapeutic.\n",
            "\n",
            "\n",
            "\n",
            "Example 7:\n",
            "\n",
            "Brief Hospital Course: The patient was admitted to the General Surgical Service on ___ for failure to thrive. The pt was started on PPN while continuing a full liquid diet (which she was able to tolerate prior to admission). On ___ the patient had a jejunostomy tube placed to facilitate nutritional support. She also had a port placed at this time for future chemotherapy treatments. The procedures went well without complication (refer to the Operative Note by Dr. ___ details). After a brief, uneventful stay in the PACU, the patient returned to the floor. On POD1 she began tube feeds, which she tolerated well. She also resumed a clear liquid diet without complication. She remained stable throughout her stay and was discharged on tube feeds and clear liquids on POD#2, HD#6. Neuro: The patient received toradol and morphine with good effect and adequate pain control. When tolerating oral intake, the patient was transitioned to oral pain medications. CV: The patient remained stable from a cardiovascular standpoint; vital signs were routinely monitored. Pulmonary: The patient remained stable from a pulmonary standpoint; vital signs were routinely monitored. Good pulmonary toilet, early ambulation and incentive spirometry were encouraged throughout hospitalization. GI/GU/FEN: The pt was started on PPN on admission while continuing a full liquid diet. The nutrition team followed the patient throughout her stay. Post-operatively, the patient was made NPO with IV fluids. Diet was advanced to clear liquids when appropriate, which was well tolerated. Pt was started on tube feeds on POD#1, starting at 10cc/hr and advanced to goal 70cc/hr. Her feeds will be cycled over 10 hours at home. Patient's intake and output were closely monitored, and IV fluid was adjusted when necessary. Electrolytes were routinely followed, and repleted when necessary. ID: The patient's white blood count and fever curves were closely watched for signs of infection. The wound dressings were changed daily. Hematology: The patient's complete blood count was examined routinely; no transfusions were required. Prophylaxis: The patient received subcutaneous heparin and venodyne boots were used during this stay; was encouraged to get up and ambulate as early as possible. At the time of discharge, the patient was doing well, afebrile with stable vital signs. The patient was tolerating a clear liquid diet and tube feeds, ambulating, voiding without assistance, and pain was well controlled. The patient received discharge teaching and follow-up instructions with understanding verbalized and agreement with the discharge plan.\n",
            "\n",
            "You were admitted to ___ to receive supplemental nutrition prior to starting chemotherapy. You had a J-tube placed in your small intestine to receive additional tube feeds, and a port placed that will be used for your future chemotherapy treatments. You tolerated both of these procedures very well and are recovering nicely. Your tube feeds were started slowly in the hospital and advanced to your goal rate. You will continue tube feeds at home, cycled over 10 hours per day. Flush the J-tube with 100mL of water before and after each feed. You will have a visiting nurse to help you with your tube feeds, and an outpatient dietician to monitor your nutrition.\n",
            "\n",
            "You were admitted to the hospital for failure to thrive. You were started on PPN (nutrition through your vein) and were started on tube feeds. You had a jejunostomy tube placed to facilitate nutritional support. You also had a port placed at this time for future chemotherapy treatments. The procedures went well without complication. You are now tolerating a clear liquid diet and tube feeds. You are now ready to be discharged to continue your recovery at home. You will be given a prescription for tube feeds. You will be given a prescription for a prescription for a prescription for tube feeds. You will be given a prescription for a prescription for a prescription for a prescription for tube feeds.\n",
            "\n",
            "\n",
            "\n",
            "Example 8:\n",
            "\n",
            "Brief Hospital Course: This is a ___ woman with history of severe aortic stenosis, diabetes, hypertension, hyperlipidemia, CAD s/p 2 drug-eluting stents in RCA and LCx on ___ who presented with two days of abdominal pain after 1 week of empiric levaquin treatment for presumed cellulitis. . # Abdominal pain: The patient reported having increased gas and loose BMs for the past week and severe abdominal pain for one day. On admission she had significant leukocytosis with WBC 23, which trended down to 9.9 at discharge. CT imaging was suggestive of segmental transverse colon thickening (opposite side from pain), concerning for diverticulitis or possible neoplasm. Stool was negative for C. diff toxin and stool cultures were pending at time of discharge. She was started on a 10-day course of ciprofloxacin and metronidazole which she will complete at home. It was recommended that she have a colonoscopy as an outpatient for further evaluation, an appointment was made as detailed below. The patient's last colonoscopy was in ___, and showed a polyp in the transverse colon. . #Hypotension: During her hospital stay, the patient was triggered for a blood pressure of 75/26 with heartrate of 44. EKG showed junctional escape rhythm, without ischemic changes. Metoprolol was discontinued and diltiazem was decreased from 240mg ER ___ to 60mg TID. Her BP and HR returned to her baseline. She was monitored overnight on telemetry and had no additional triggers. She remained asymptomatic. She is scheduled to follow-up with cardiology in 2 weeks after discharge. Further titration of her dilt and BB should be continued at rehab and by Dr ___ . ___ erythema: The patient presented with bilateral lower extremity erythema, which was nontender but warm to touch. These findings were noted during her previous admission. This was thought to be venous stasis given its bilateral nature. She was encouraged to keep her legs elevated as much as possible and to contact her PCP if the area worsens. The pt was without SOB, JVD. Diuresis was defered in the setting of low BP as explained above. . # Chronic diastolic heart failure: CCB and BB meds adjusted as explained above. Pt had ___ edema, however no SOB, JVD, or other symptoms of CHF. Diuresis was defered in the setting of low BP as explained above. . # CAD: The patient is s/p placement of two drug-eluting stents on ___. During her stay she denied chest pain or pressure. She also stated that her abdominal discomfort is unlike discomfort she had in the past with ischemia. Cardiac enzymes were negative x2 and EKG was unchanged from previous EKG. She was continued on her home medications ASA, clopidogrel, metoprolol, lisinopril, and atorvastatin. . # Rythem: Pt was found to be in junctional escape rythem ___ excessive AV nodal blocking medications. The patient returned to sinus rythem after discontinuation of the BB and decreasing the CCB although she continues to have frequent couplets and triplets on tele. The pt had SVT and atrial tachycardia during her last admission, therefore her medicines and HR should be closely monitored. . # DM: The patient has a history of diabetes mellitus controlled on glyburide. During her stay her glyburide was held and she was treated with an insulin sliding scale. . #Hypertension: The patient's blood pressures were well controlled on her home medications lisinopril, diltiazem, metoprolol. . # FEN: The patient tolerated clears and was allowed to advance her diet as tolerated. Potassium on admission was 5.7., trended down, but back to 5.0 on discharge. Potassium levels should be followed in rehab. . # PPx: She received heparin SC for DVT prophylaxis.\n",
            "\n",
            "You were admitted to the hospital because you were having stomach pain. While you were here, you had a chest Xray which was negative and cardiac enzymes (a test for heart damage) which were negative. Your CT scan showed an area of inflammation in your colon, which may be diverticulitis. You were treated with ciprofloxacin and metronidazole (antibiotics for diverticulitis). Your stomach pain improved while you were here. However we recommend that you have a colonoscopy as an outpatient. See below for your appointments. While you were here, you had a drop in blood pressure to ___ with a slow heart rate of 44. To treat this, your metoprolol (one of your blood pressure medications) was stopped, and your diltiazem (another blood pressure medication) was decreased. Your blood pressure and heart rate returned to normal overnight.\n",
            "\n",
            "You were admitted to the hospital for abdominal pain. You were found to have a skin infection called cellulitis. You were started on antibiotics and your symptoms improved. You were also found to have a low blood pressure. Your blood pressure medication, metoprolol, was decreased and your heart rate was controlled. You were also found to have a small polyp in your colon. You should have a colonoscopy as an outpatient. During your stay you were found to have a low heart rate. Your heart rate was controlled with medications. You should continue to take these medications at rehab.\n",
            "\n",
            "\n",
            "\n",
            "Example 9:\n",
            "\n",
            "Brief Hospital Course: ___ yo F w/ hx of EtOH cirrhosis, currently decompensated by diuretic-refractory ascites (requiring <q2 week paracentesis), bleeding esophageal varices (resulting in PEA arrest from hemorrhagic shock, ___, hx of hepatic encephalopathy (now well-controlled), not listed for transplant ___ psychosocial concerns (inconsistent care, immigration status) admitted with massive ascites for therapeutic paracentesis. She has been repeatedly hospitalized for therapeutic paracentesis despite attempts to connect her with outpatient care for the same. In addition to performing therapeutic paracentesis (6L on ___, this hospitalization focused on care that she otherwise needs for alcoholic cirrhosis (EGD follow-up for varices on ___ banded x 1 w/ next EGD due in 3 months). Transitional issues of note: - Serial para: requires paracentesis more frequently than q2 weeks. Now has ___ Essential, so insurance should not be limiting. Scheduled for outpatient para (6L) w/ ___ on ___. - ___: As at prior admissions, noted to have ___ on admission (Cr 1.4 from baseline <1.0) despite downtitration of diuretics (lasix 100->40, spironolactone 200->50) at last admission. Cr resolved to 1.0 w/ holding diuretics and BB, and w/ albumin resuscitation. Discharged OFF all diuretics. - Variceal ppx: given marginal BPs (requires midodrine to maintain BPs 90/50) and recurrent ___, discharged OFF nadolol.\n",
            "\n",
            "You were admitted to the hospital with swelling of your belly due to ascites and liver disease. We took out 6 liters of fluid from your belly on ___ (with a procedure called a paracentesis). On ___ you had a test called an endoscopy (also called EGD) where they put a camera into the stomach to look for blood vessels that could bleed (called varices). During this test they put bands on the blood vessels that they saw to prevent another gastrointestinal bleed like the one you had in ___. You are due for your next endoscopy in ___. We scheduled your next paracentesis for next ___. In the future, you will have weekly paracenteses as an outpatient and will not need to come into the hospital in order to get your belly drained. We noticed that your kidneys were not functioning well when you came into the hospital. This is probably because you were dehydrated from the water pills (furosemide and spironolactone) that you were taking before, even though we decreased the dose at your last hospitalization. Please STOP taking both furosemide and spironolactone. In addition, please STOP taking nadolol, since we also believe this medication could be hurting your kidneys.\n",
            "\n",
            "You were admitted to the hospital for a therapeutic paracentesis to remove fluid from your abdomen. You have had multiple attempts to do this in the past, but have not been able to connect with the same outpatient providers. In addition to performing therapeutic paracentesis (6L) on ___, this hospitalization focused on care that you otherwise need for alcoholic cirrhosis (EGD follow-up for varices on ___ banded x 1 w/ next EGD due in 3 months). You were discharged on ___ for a therapeutic paracentesis (6L) on ___. You will need to come back to the hospital for a repeat paracentesis on ___.\n",
            "Test metrics:\n",
            "defaultdict(<class 'list'>, {'rouge1': 43.25396646797377, 'rouge2': 15.954881169993223, 'rouge3': 7.9714798504968885, 'rouge4': 4.890290280960895, 'rougeL': 27.57060317593533, 'words': 117.38, 'bert_score': 86.8378359079361, 'bert_score_deberta-large': 60.8961663544178, 'sari': 45.675860998078015})\n",
            "$43.25$ & $15.95$ & $7.97$ & $4.89$ & $27.57$ & $86.84$ & $60.90$ & $45.68$ & $117.38$\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               bert_score ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: bert_score_deberta-large ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge1 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge2 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge3 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge4 ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rougeL ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     sari ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    words ▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               bert_score 86.83784\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: bert_score_deberta-large 60.89617\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge1 43.25397\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge2 15.95488\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge3 7.97148\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rouge4 4.89029\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                   rougeL 27.5706\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                     sari 45.67586\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                    words 117.38\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /content/patient_summaries_with_llms/wandb/offline-run-20251206_103254-5gqrwl15\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20251206_103254-5gqrwl15/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# # @title LED-base on train_last_100 / valid_last_100\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "DATA_DIR = Path(\"data/ann-pt-summ/1.0.1/mimic-iv-note-ext-di-bhc/dataset\")\n",
        "\n",
        "assert DATA_DIR.exists(), f\"Missing dataset folder: {DATA_DIR}\"\n",
        "\n",
        "    # --do_train --do_eval --do_predict \\\n",
        "!python summarization/run_summarization.py \\\n",
        "    --model_name_or_path data/led_4000_600_chars/ \\\n",
        "    --test_file {DATA_DIR / 'test_4000_600_chars_last_100.json'} \\\n",
        "    --text_column text \\\n",
        "    --summary_column summary \\\n",
        "    --output_dir results/led_full_run_predict \\\n",
        "    --do_predict \\\n",
        "    --predict_with_generate \\\n",
        "    --per_device_eval_batch_size 1 \\\n",
        "    --max_source_length 4096 \\\n",
        "    --max_target_length 350 \\\n",
        "    --report_to none"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}